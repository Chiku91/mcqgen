{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (0.3.14)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from langchain-community) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from langchain-community) (3.11.11)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from langchain-community) (0.3.14)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from langchain-community) (0.3.29)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from langchain-community) (0.2.10)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from langchain-community) (2.7.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.25.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from langchain<0.4.0,>=0.3.14->langchain-community) (0.3.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from langchain<0.4.0,>=0.3.14->langchain-community) (2.10.5)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.14)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community) (2.27.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\asus\\desktop\\mcqgen\\env\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check if a specific environment variable is loaded\n",
    "env_var = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Output True if the environment variable is loaded, False otherwise\n",
    "print(env_var is not None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI(openai_api_key=KEY,model_name=\"gpt-4.0-turbo\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000281BC645890>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000281BC64D750>, model_name='gpt-4.0-turbo', temperature=0.5, model_kwargs={}, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\"\n",
    "        }\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\"\n",
    "        },\n",
    "        \"correct\": \"correct answer\"\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\"\n",
    "        },\n",
    "        \"correct\": \"correct answer\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker, Given the above text, it is your job to create a quiz of {number} multiple choice questions for {subject} students in {tone} tone.\n",
    "Make sure that the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like RESPONSE_JSON below and use it as a guide. \n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\",\"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template=TEMPLATE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2 = \"\"\"\n",
    "You are an expert English grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
    "If the quiz is not at par with the cognitive and analytical abilities of the students,\n",
    "update the quiz questions that need to be changed and change the tone such that it perfectly fits the student abilities.\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"subject\", \"quiz\"],\n",
    "    template=TEMPLATE2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain = LLMChain(llm=llm, prompt=quiz_generation_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain = LLMChain(llm=llm, prompt=quiz_evaluation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Quiz:\n",
      "\n",
      "\n",
      "Review of the Quiz:\n",
      "Complexity Analysis: The quiz questions are straightforward and test basic programming concepts. They are suitable for beginners and do not require high-level analytical skills. The language used is clear and easy to understand.\n",
      "\n",
      "Updated Questions:\n",
      "1. Which of the following is NOT a programming language?\n",
      "   A) Python\n",
      "   B) Java\n",
      "   C) HTML\n",
      "   D) Microsoft Excel\n",
      "\n",
      "2. What does HTML stand for?\n",
      "   A) Hyper Text Markup Language\n",
      "   B) High Tech Modern Language\n",
      "   C) Hard To Master Language\n",
      "   D) Home Tool Making Language\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Define the first template for quiz generation\n",
    "TEMPLATE = \"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker, Given the above text, it is your job to create a quiz of {number} multiple choice questions for {subject} students in {tone} tone.\n",
    "Make sure that the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like RESPONSE_JSON below and use it as a guide. \n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\"\"\"\n",
    "\n",
    "# Define the second template for quiz evaluation\n",
    "TEMPLATE2 = \"\"\"\n",
    "You are an expert English grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
    "If the quiz is not at par with the cognitive and analytical abilities of the students,\n",
    "update the quiz questions that need to be changed and change the tone such that it perfectly fits the student abilities.\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the prompt templates\n",
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template=TEMPLATE\n",
    ")\n",
    "\n",
    "quiz_evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"subject\", \"quiz\"],  # Only subject and quiz are needed for review chain\n",
    "    template=TEMPLATE2\n",
    ")\n",
    "\n",
    "# Initialize the LLM model (e.g., OpenAI GPT-3.5)\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Create quiz generation chain (this generates the quiz)\n",
    "quiz_chain = LLMChain(llm=llm, prompt=quiz_generation_prompt)\n",
    "\n",
    "# Create review generation chain (this evaluates the quiz)\n",
    "review_chain = LLMChain(llm=llm, prompt=quiz_evaluation_prompt)\n",
    "\n",
    "# Example input for the chain\n",
    "input_data = {\n",
    "    \"text\": \"Python programming\",  # This is necessary for the quiz generation\n",
    "    \"number\": 5,\n",
    "    \"subject\": \"Programming\",\n",
    "    \"tone\": \"friendly\",\n",
    "    \"response_json\": '{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}}}'\n",
    "}\n",
    "\n",
    "# Step 1: Generate the quiz using the first chain\n",
    "quiz_output = quiz_chain.run(input_data)  # run method directly on the chain\n",
    "\n",
    "# Step 2: Check the type of `quiz_output` to ensure it's a valid dictionary or JSON\n",
    "try:\n",
    "    quiz_output_dict = eval(quiz_output)  # Convert the string output to a dictionary (assuming it is valid JSON)\n",
    "except Exception as e:\n",
    "    print(f\"Error parsing quiz output as JSON: {e}\")\n",
    "    quiz_output_dict = {}\n",
    "\n",
    "# Extract the generated quiz from the output\n",
    "quiz = quiz_output_dict.get(\"quiz\", \"\")\n",
    "\n",
    "# Step 2: Evaluate the quiz using the second chain (passing the quiz output from step 1)\n",
    "evaluation_input = {\n",
    "    \"subject\": input_data['subject'],\n",
    "    \"quiz\": quiz\n",
    "}\n",
    "\n",
    "review_output = review_chain.run(evaluation_input)\n",
    "\n",
    "# Print the result (this will include both the quiz and the review)\n",
    "print(\"Generated Quiz:\")\n",
    "print(quiz)\n",
    "\n",
    "print(\"\\nReview of the Quiz:\")\n",
    "print(review_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=r\"C:\\Users\\ASUS\\Desktop\\mcqgen\\data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'r') as file:\n",
    "    TEXT = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and pioneer in the field of computer gaming and artificial intelligence.[8][9] The synonym self-teaching computers was also used in this time period.[10][11]\n",
      "\n",
      "Although the earliest machine learning model was introduced in the 1950s when Arthur Samuel invented a program that calculated the winning chance in checkers for each side, the history of machine learning roots back to decades of human desire and effort to study human cognitive processes.[12] In 1949, Canadian psychologist Donald Hebb published the book The Organization of Behavior, in which he introduced a theoretical neural structure formed by certain interactions among nerve cells.[13] Hebb's model of neurons interacting with one another set a groundwork for how AIs and machine learning algorithms work under nodes, or artificial neurons used by computers to communicate data.[12] Other researchers who have studied human cognitive systems contributed to the modern machine learning technologies as well, including logician Walter Pitts and Warren McCulloch, who proposed the early mathematical models of neural networks to come up with algorithms that mirror human thought processes.[12]\n",
      "\n",
      "By the early 1960s, an experimental \"learning machine\" with punched tape memory, called Cybertron, had been developed by Raytheon Company to analyse sonar signals, electrocardiograms, and speech patterns using rudimentary reinforcement learning. It was repetitively \"trained\" by a human operator/teacher to recognize patterns and equipped with a \"goof\" button to cause it to reevaluate incorrect decisions.[14] A representative book on research into machine learning during the 1960s was Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification.[15] Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973.[16] In 1981 a report was given on using teaching strategies so that an artificial neural network learns to recognize 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.[17]\n",
      "\n",
      "Tom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E.\"[18] This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing's proposal in his paper \"Computing Machinery and Intelligence\", in which the question \"Can machines think?\" is replaced with the question \"Can machines do what we (as thinking entities) can do?\".[19]\n",
      "\n",
      "Modern-day machine learning has two objectives. One is to classify data based on models which have been developed; the other purpose is to make predictions for future outcomes based on these models. A hypothetical algorithm specific to classifying data may use computer vision of moles coupled with supervised learning in order to train it to classify the cancerous moles. A machine learning algorithm for stock trading may inform the trader of future potential predictions.\n"
     ]
    }
   ],
   "source": [
    "print(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Serialize the python dictonary into a Json-formated string\n",
    "import json\n",
    "json.dumps(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw response from quiz generation chain:\n",
      "{\n",
      "  \"quiz\": [\n",
      "    {\n",
      "      \"mcq\": \"Who coined the term 'machine learning' in 1959?\",\n",
      "      \"options\": {\n",
      "        \"a\": \"Donald Hebb\",\n",
      "        \"b\": \"Raytheon Company\",\n",
      "        \"c\": \"Arthur Samuel\",\n",
      "        \"d\": \"Tom M. Mitchell\"\n",
      "      } ,\n",
      "      \"answer\": \"c\"\n",
      "    },\n",
      "    {\n",
      "      \"mcq\": \"What was the name of the experimental 'learning machine' developed by Raytheon Company in the early 1960s?\",\n",
      "      \"options\": {\n",
      "        \"a\": \"Cybertron\",\n",
      "        \"b\": \"HAL 9000\",\n",
      "        \"c\": \"Deep Blue\",\n",
      "        \"d\": \"Skynet\"\n",
      "      } ,\n",
      "      \"answer\": \"a\"\n",
      "    },\n",
      "    {\n",
      "      \"mcq\": \"Who proposed the early mathematical models of neural networks to mirror human thought processes?\",\n",
      "      \"options\": {\n",
      "        \"a\": \"Walter Pitts and Warren McCulloch\",\n",
      "        \"b\": \"Donald Hebb\",\n",
      "        \"c\": \"Tom M. Mitchell\",\n",
      "        \"d\": \"Arthur Samuel\"\n",
      "      } ,\n",
      "      \"answer\": \"a\"\n",
      "    },\n",
      "    {\n",
      "      \"mcq\": \"Which book in the 1960s focused on machine learning for pattern classification?\",\n",
      "      \"options\": {\n",
      "        \"a\": \"The Organization of Behavior\",\n",
      "        \"b\": \"Computing Machinery and Intelligence\",\n",
      "        \"c\": \"Learning Machines\",\n",
      "        \"d\": \"Artificial Intelligence: A Modern Approach\"\n",
      "      } ,\n",
      "      \"answer\": \"c\"\n",
      "    },\n",
      "    {\n",
      "      \"mcq\": \"According to Tom M. Mitchell, what is the definition of a computer program learning from experience?\",\n",
      "      \"options\": {\n",
      "        \"a\": \"Improving its performance at tasks in T\",\n",
      "        \"b\": \"Developing new algorithms\",\n",
      "        \"c\": \"Reevaluating incorrect decisions\",\n",
      "        \"d\": \"Classifying data based on models\"\n",
      "      } ,\n",
      "      \"answer\": \"a\"\n",
      "    },\n",
      "    {\n",
      "      \"mcq\": \"What is one of the objectives of modern-day machine learning?\",\n",
      "      \"options\": {\n",
      "        \"a\": \"Developing new programming languages\",\n",
      "        \"b\": \"Predicting future outcomes based on models\",\n",
      "        \"c\": \"Creating complex neural structures\",\n",
      "        \"d\": \"Analyzing historical data\"\n",
      "      } ,\n",
      "      \"answer\": \"b\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Generated Quiz:\n",
      "{\n",
      "    \"quiz\": [\n",
      "        {\n",
      "            \"mcq\": \"Who coined the term 'machine learning' in 1959?\",\n",
      "            \"options\": {\n",
      "                \"a\": \"Donald Hebb\",\n",
      "                \"b\": \"Raytheon Company\",\n",
      "                \"c\": \"Arthur Samuel\",\n",
      "                \"d\": \"Tom M. Mitchell\"\n",
      "            },\n",
      "            \"answer\": \"c\"\n",
      "        },\n",
      "        {\n",
      "            \"mcq\": \"What was the name of the experimental 'learning machine' developed by Raytheon Company in the early 1960s?\",\n",
      "            \"options\": {\n",
      "                \"a\": \"Cybertron\",\n",
      "                \"b\": \"HAL 9000\",\n",
      "                \"c\": \"Deep Blue\",\n",
      "                \"d\": \"Skynet\"\n",
      "            },\n",
      "            \"answer\": \"a\"\n",
      "        },\n",
      "        {\n",
      "            \"mcq\": \"Who proposed the early mathematical models of neural networks to mirror human thought processes?\",\n",
      "            \"options\": {\n",
      "                \"a\": \"Walter Pitts and Warren McCulloch\",\n",
      "                \"b\": \"Donald Hebb\",\n",
      "                \"c\": \"Tom M. Mitchell\",\n",
      "                \"d\": \"Arthur Samuel\"\n",
      "            },\n",
      "            \"answer\": \"a\"\n",
      "        },\n",
      "        {\n",
      "            \"mcq\": \"Which book in the 1960s focused on machine learning for pattern classification?\",\n",
      "            \"options\": {\n",
      "                \"a\": \"The Organization of Behavior\",\n",
      "                \"b\": \"Computing Machinery and Intelligence\",\n",
      "                \"c\": \"Learning Machines\",\n",
      "                \"d\": \"Artificial Intelligence: A Modern Approach\"\n",
      "            },\n",
      "            \"answer\": \"c\"\n",
      "        },\n",
      "        {\n",
      "            \"mcq\": \"According to Tom M. Mitchell, what is the definition of a computer program learning from experience?\",\n",
      "            \"options\": {\n",
      "                \"a\": \"Improving its performance at tasks in T\",\n",
      "                \"b\": \"Developing new algorithms\",\n",
      "                \"c\": \"Reevaluating incorrect decisions\",\n",
      "                \"d\": \"Classifying data based on models\"\n",
      "            },\n",
      "            \"answer\": \"a\"\n",
      "        },\n",
      "        {\n",
      "            \"mcq\": \"What is one of the objectives of modern-day machine learning?\",\n",
      "            \"options\": {\n",
      "                \"a\": \"Developing new programming languages\",\n",
      "                \"b\": \"Predicting future outcomes based on models\",\n",
      "                \"c\": \"Creating complex neural structures\",\n",
      "                \"d\": \"Analyzing historical data\"\n",
      "            },\n",
      "            \"answer\": \"b\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "Review of the Quiz:\n",
      "The Multiple Choice Quiz provided for Machine Learning students is well-structured and covers a range of important historical and conceptual aspects of the field. The complexity level of the questions seems appropriate for students studying machine learning, as it requires knowledge of key figures, historical developments, and core principles in the field.\n",
      "\n",
      "However, there are some areas where the quiz could be improved to better align with the cognitive and analytical abilities of the students. Here are some suggestions for updates:\n",
      "\n",
      "1. Question 2: The reference to 'HAL 9000' may be too specific and not directly related to machine learning. Consider replacing it with a more relevant option that aligns with the topic.\n",
      "\n",
      "2. Question 4: The book titles provided as options might not be familiar to all students. Consider simplifying the options or providing more context to help students make an educated guess.\n",
      "\n",
      "3. Question 6: The term \"complex neural structures\" in option C might be too advanced for some students. Consider rephrasing the options to make them more accessible and easier to understand.\n",
      "\n",
      "Overall, the quiz is comprehensive and covers important aspects of machine learning. By making some adjustments to the questions and options, the quiz can be even more effective in testing and reinforcing students' knowledge in the field.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "# Read text from file (you can provide any file path)\n",
    "file_path = r\"C:\\Users\\ASUS\\Desktop\\mcqgen\\data.txt\"\n",
    "\n",
    "# Read the content of the text file\n",
    "with open(file_path, 'r') as file:\n",
    "    TEXT = file.read()\n",
    "\n",
    "# Define the first template for quiz generation\n",
    "TEMPLATE = \"\"\"\n",
    "Text: {text}\n",
    "You are an expert MCQ maker. Given the above text, create exactly {number} multiple choice questions for {subject} students in a {tone} tone. \n",
    "Each question should be unique and related to the text. Ensure that all questions are clear, unambiguous, and well-formed, ensuring that each question is of good quality.\n",
    "The format for the response should strictly follow this structure:\n",
    "{{\n",
    "  \"quiz\": [\n",
    "    {{\n",
    "      \"mcq\": \"Your question here\",\n",
    "      \"options\": {{\n",
    "        \"a\": \"Choice A\",\n",
    "        \"b\": \"Choice B\",\n",
    "        \"c\": \"Choice C\",\n",
    "        \"d\": \"Choice D\"\n",
    "      }} ,\n",
    "      \"answer\": \"correct answer\"\n",
    "    }} \n",
    "  ]\n",
    "}}\n",
    "Ensure that there are {number} MCQs and no more than that. If less than {number} MCQs are generated, continue generating until the exact number is produced.\n",
    "\"\"\"\n",
    "\n",
    "# Define the second template for quiz evaluation\n",
    "TEMPLATE2 = \"\"\"\n",
    "You are an expert English grammarian and writer. Given a Multiple Choice Quiz for {subject} students, evaluate the complexity of the questions and provide a complete analysis of the quiz.\n",
    "If the quiz is not at par with the cognitive and analytical abilities of the students, update the quiz questions that need to be changed and adjust the tone so it perfectly fits the student abilities.\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the prompt templates\n",
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\"],\n",
    "    template=TEMPLATE\n",
    ")\n",
    "\n",
    "quiz_evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"subject\", \"quiz\"],  # Only subject and quiz are needed for review chain\n",
    "    template=TEMPLATE2\n",
    ")\n",
    "\n",
    "# Initialize the LLM model (e.g., OpenAI GPT-3.5)\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Create quiz generation chain (this generates the quiz)\n",
    "quiz_chain = LLMChain(llm=llm, prompt=quiz_generation_prompt)\n",
    "\n",
    "# Create review generation chain (this evaluates the quiz)\n",
    "review_chain = LLMChain(llm=llm, prompt=quiz_evaluation_prompt)\n",
    "\n",
    "# User-defined inputs\n",
    "NUMBER = 6 # Number of MCQs the user wants\n",
    "SUBJECT = \"Machine Learning\"\n",
    "TONE = \"harder\"\n",
    "\n",
    "# Define the callback function to log the result\n",
    "def openai_callback(result, *args, **kwargs):\n",
    "    print(\"OpenAI Callback triggered!\")\n",
    "    print(f\"Result: {result}\")\n",
    "\n",
    "# Use get_openai_callback directly and capture the output- Tracking token usage\n",
    "with get_openai_callback() as callback:\n",
    "    # Step 1: Generate the quiz using the first chain\n",
    "    input_data = {\n",
    "        \"text\": TEXT,  # Read text from file dynamically\n",
    "        \"number\": NUMBER,\n",
    "        \"subject\": SUBJECT,\n",
    "        \"tone\": TONE\n",
    "    }\n",
    "\n",
    "    # Run the quiz generation chain\n",
    "    quiz_output = \"\"\n",
    "    while True:\n",
    "        try:\n",
    "            # Generate the quiz\n",
    "            quiz_output = quiz_chain.run(input_data)  # Run the chain to generate the quiz\n",
    "\n",
    "            # Log the raw output from the quiz generation chain for inspection\n",
    "            print(\"Raw response from quiz generation chain:\")\n",
    "            print(quiz_output)\n",
    "\n",
    "            # Check if the output is empty\n",
    "            if not quiz_output.strip():\n",
    "                print(\"Error: Received empty response from the quiz generation model.\")\n",
    "                quiz_output_dict = {}\n",
    "            else:\n",
    "                # Try parsing the response as JSON\n",
    "                try:\n",
    "                    # Attempt to load the response as JSON (this is now more strict)\n",
    "                    quiz_output_dict = json.loads(quiz_output)  # Parse the output as JSON\n",
    "\n",
    "                    # Check if the generated quiz contains the correct number of MCQs\n",
    "                    quiz_list = quiz_output_dict.get(\"quiz\", [])\n",
    "                    if len(quiz_list) >= NUMBER:\n",
    "                        break  # Exit the loop if we have enough questions\n",
    "                    else:\n",
    "                        print(f\"Generated {len(quiz_list)} MCQs, but {NUMBER} are required. Re-generating...\")\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error parsing quiz output as JSON: {e}\")\n",
    "                    print(f\"Raw output received: {quiz_output}\")  # Print the raw output for debugging\n",
    "                    quiz_output_dict = {}\n",
    "        except Exception as e:\n",
    "            print(f\"Error during quiz generation: {e}\")\n",
    "            quiz_output_dict = {}\n",
    "\n",
    "    # If quiz output is empty or doesn't contain valid data, handle gracefully\n",
    "    if not quiz_output_dict:\n",
    "        print(\"Error: Generated quiz output is empty or invalid.\")\n",
    "        quiz = \"\"\n",
    "    else:\n",
    "        # Extract the generated quiz from the output\n",
    "        quiz = json.dumps(quiz_output_dict, indent=4)\n",
    "\n",
    "    # Step 3: Evaluate the quiz using the second chain (passing the quiz output from step 1)\n",
    "    if quiz:\n",
    "        evaluation_input = {\n",
    "            \"subject\": SUBJECT,\n",
    "            \"quiz\": quiz\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # Run the review chain to evaluate the quiz\n",
    "            review_output = review_chain.run(evaluation_input)\n",
    "\n",
    "            # Print the result (this will include both the quiz and the review)\n",
    "            print(\"Generated Quiz:\")\n",
    "            print(quiz)\n",
    "\n",
    "            print(\"\\nReview of the Quiz:\")\n",
    "            print(review_output)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during quiz evaluation: {e}\")\n",
    "    else:\n",
    "        print(\"No quiz generated, skipping evaluation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens:2190\n",
      "Prompt Tokens:1432\n",
      "Completion Tokens:758\n",
      "Total Cost:0.003664\n"
     ]
    }
   ],
   "source": [
    "# Total Tokens\n",
    "print(f\"Total Tokens:{callback.total_tokens}\")    \n",
    "# Input Token\n",
    "print(f\"Prompt Tokens:{callback.prompt_tokens}\")\n",
    "# Output Token\n",
    "print(f\"Completion Tokens:{callback.completion_tokens}\")\n",
    "# Total Cost\n",
    "print(f\"Total Cost:{callback.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw response from quiz generation chain:\n",
      "{\n",
      "  \"quiz\": [\n",
      "    {\n",
      "      \"mcq\": \"Who coined the term 'machine learning' in 1959?\",\n",
      "      \"options\": {\n",
      "        \"a\": \"Donald Hebb\",\n",
      "        \"b\": \"Tom M. Mitchell\",\n",
      "        \"c\": \"Arthur Samuel\",\n",
      "        \"d\": \"Walter Pitts\"\n",
      "      },\n",
      "      \"answer\": \"c\"\n",
      "    },\n",
      "    {\n",
      "      \"mcq\": \"What was the name of the experimental 'learning machine' developed by Raytheon Company in the early 1960s?\",\n",
      "      \"options\": {\n",
      "        \"a\": \"Cybernet\",\n",
      "        \"b\": \"Cybertron\",\n",
      "        \"c\": \"Cyberspace\",\n",
      "        \"d\": \"Cyberlink\"\n",
      "      },\n",
      "      \"answer\": \"b\"\n",
      "    },\n",
      "    {\n",
      "      \"mcq\": \"Who proposed the early mathematical models of neural networks in the study of human cognitive systems?\",\n",
      "      \"options\": {\n",
      "        \"a\": \"Donald Hebb\",\n",
      "        \"b\": \"Warren McCulloch\",\n",
      "        \"c\": \"Tom M. Mitchell\",\n",
      "        \"d\": \"Raytheon Company\"\n",
      "      },\n",
      "      \"answer\": \"b\"\n",
      "    },\n",
      "    {\n",
      "      \"mcq\": \"According to Tom M. Mitchell, what is the definition of a computer program learning from experience?\",\n",
      "      \"options\": {\n",
      "        \"a\": \"Improving performance with respect to tasks\",\n",
      "        \"b\": \"Improving performance with respect to experience\",\n",
      "        \"c\": \"Improving performance with respect to performance measure\",\n",
      "        \"d\": \"Improving performance with respect to class of tasks\"\n",
      "      },\n",
      "      \"answer\": \"a\"\n",
      "    },\n",
      "    {\n",
      "      \"mcq\": \"What are the two objectives of modern-day machine learning?\",\n",
      "      \"options\": {\n",
      "        \"a\": \"Predicting past outcomes and classifying data\",\n",
      "        \"b\": \"Classifying data and making predictions for future outcomes\",\n",
      "        \"c\": \"Training models and developing algorithms\",\n",
      "        \"d\": \"Analyzing data and predicting future trends\"\n",
      "      },\n",
      "      \"answer\": \"b\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Generated Quiz (as List):\n",
      "1. Who coined the term 'machine learning' in 1959?\n",
      "    a: Donald Hebb\n",
      "    b: Tom M. Mitchell\n",
      "    c: Arthur Samuel\n",
      "    d: Walter Pitts\n",
      "    Answer: c\n",
      "\n",
      "2. What was the name of the experimental 'learning machine' developed by Raytheon Company in the early 1960s?\n",
      "    a: Cybernet\n",
      "    b: Cybertron\n",
      "    c: Cyberspace\n",
      "    d: Cyberlink\n",
      "    Answer: b\n",
      "\n",
      "3. Who proposed the early mathematical models of neural networks in the study of human cognitive systems?\n",
      "    a: Donald Hebb\n",
      "    b: Warren McCulloch\n",
      "    c: Tom M. Mitchell\n",
      "    d: Raytheon Company\n",
      "    Answer: b\n",
      "\n",
      "4. According to Tom M. Mitchell, what is the definition of a computer program learning from experience?\n",
      "    a: Improving performance with respect to tasks\n",
      "    b: Improving performance with respect to experience\n",
      "    c: Improving performance with respect to performance measure\n",
      "    d: Improving performance with respect to class of tasks\n",
      "    Answer: a\n",
      "\n",
      "5. What are the two objectives of modern-day machine learning?\n",
      "    a: Predicting past outcomes and classifying data\n",
      "    b: Classifying data and making predictions for future outcomes\n",
      "    c: Training models and developing algorithms\n",
      "    d: Analyzing data and predicting future trends\n",
      "    Answer: b\n",
      "\n",
      "\n",
      "Review of the Quiz:\n",
      "The above Multiple Choice Quiz on Machine Learning seems to be well-structured and covers a range of topics related to the history and concepts of machine learning. The questions are designed to test the knowledge and understanding of students in this field. \n",
      "\n",
      "However, there are a few aspects that could be improved to make the quiz more suitable for programming students:\n",
      "\n",
      "1. Complexity: Some of the questions may be a bit too advanced for beginner programming students. For example, the question about the mathematical models of neural networks might require more in-depth knowledge than what is typically expected from students at an introductory level.\n",
      "\n",
      "2. Clarity: The options provided for each question should be clear and distinct to avoid confusion. In some cases, such as the question about the objectives of modern-day machine learning, the options could be more precise to make the correct answer easier to identify.\n",
      "\n",
      "3. Tone and Language: The language used in the quiz should be simple and straightforward, especially considering that the target audience is programming students. Complex terminology or jargon should be avoided or explained clearly to ensure understanding.\n",
      "\n",
      "To adjust the quiz for programming students, the following changes could be made:\n",
      "\n",
      "- Simplify the language used in the questions and options to make them more accessible to students.\n",
      "- Consider including more basic concepts and definitions related to machine learning to cater to the skill level of the students.\n",
      "- Provide more context or explanations for certain terms or concepts that may be unfamiliar to beginner students.\n",
      "- Ensure that the options provided for each question are distinct and clearly differentiate the correct answer.\n",
      "\n",
      "By making these adjustments, the quiz can be better tailored to the cognitive and analytical abilities of programming students, allowing them to effectively test their knowledge and understanding of machine learning concepts.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "# Read text from file (you can provide any file path)\n",
    "file_path = r\"C:\\Users\\ASUS\\Desktop\\mcqgen\\data.txt\"\n",
    "\n",
    "# Read the content of the text file\n",
    "with open(file_path, 'r') as file:\n",
    "    TEXT = file.read()\n",
    "\n",
    "# Define the first template for quiz generation\n",
    "TEMPLATE = \"\"\"\n",
    "Text: {text}\n",
    "You are an expert MCQ maker. Given the above text, create exactly {number} multiple choice questions for {subject} students in a {tone} tone. \n",
    "Each question should be unique and related to the text. Ensure that all questions are clear, unambiguous, and well-formed, ensuring that each question is of good quality.\n",
    "The format for the response should strictly follow this structure:\n",
    "{{\n",
    "  \"quiz\": [\n",
    "    {{\n",
    "      \"mcq\": \"Your question here\",\n",
    "      \"options\": {{\n",
    "        \"a\": \"Choice A\",\n",
    "        \"b\": \"Choice B\",\n",
    "        \"c\": \"Choice C\",\n",
    "        \"d\": \"Choice D\"\n",
    "      }},\n",
    "      \"answer\": \"correct answer\"\n",
    "    }} \n",
    "  ]\n",
    "}}\n",
    "Ensure that there are {number} MCQs and no more than that. If less than {number} MCQs are generated, continue generating until the exact number is produced.\n",
    "\"\"\"\n",
    "\n",
    "# Define the second template for quiz evaluation\n",
    "TEMPLATE2 = \"\"\"\n",
    "You are an expert English grammarian and writer. Given a Multiple Choice Quiz for {subject} students, evaluate the complexity of the questions and provide a complete analysis of the quiz.\n",
    "If the quiz is not at par with the cognitive and analytical abilities of the students, update the quiz questions that need to be changed and adjust the tone so it perfectly fits the student abilities.\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the prompt templates\n",
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\"],\n",
    "    template=TEMPLATE\n",
    ")\n",
    "\n",
    "quiz_evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"subject\", \"quiz\"],  # Only subject and quiz are needed for review chain\n",
    "    template=TEMPLATE2\n",
    ")\n",
    "\n",
    "# Initialize the LLM model (e.g., OpenAI GPT-3.5)\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Create quiz generation chain (this generates the quiz)\n",
    "quiz_chain = LLMChain(llm=llm, prompt=quiz_generation_prompt)\n",
    "\n",
    "# Create review generation chain (this evaluates the quiz)\n",
    "review_chain = LLMChain(llm=llm, prompt=quiz_evaluation_prompt)\n",
    "\n",
    "# User-defined inputs\n",
    "NUMBER = 5  # Number of MCQs the user wants\n",
    "SUBJECT = \"Programming\"\n",
    "TONE = \"friendly\"\n",
    "\n",
    "# Define the callback function to log the result\n",
    "def openai_callback(result, *args, **kwargs):\n",
    "    print(\"OpenAI Callback triggered!\")\n",
    "    print(f\"Result: {result}\")\n",
    "\n",
    "# Use get_openai_callback directly and capture the output\n",
    "with get_openai_callback() as callback:\n",
    "    # Step 1: Generate the quiz using the first chain\n",
    "    input_data = {\n",
    "        \"text\": TEXT,  # Read text from file dynamically\n",
    "        \"number\": NUMBER,\n",
    "        \"subject\": SUBJECT,\n",
    "        \"tone\": TONE\n",
    "    }\n",
    "\n",
    "    # Run the quiz generation chain\n",
    "    quiz_output = \"\"\n",
    "    while True:\n",
    "        try:\n",
    "            # Generate the quiz\n",
    "            quiz_output = quiz_chain.run(input_data)  # Run the chain to generate the quiz\n",
    "\n",
    "            # Log the raw output from the quiz generation chain for inspection\n",
    "            print(\"Raw response from quiz generation chain:\")\n",
    "            print(quiz_output)\n",
    "\n",
    "            # Check if the output is empty\n",
    "            if not quiz_output.strip():\n",
    "                print(\"Error: Received empty response from the quiz generation model.\")\n",
    "                quiz_output_dict = {}\n",
    "            else:\n",
    "                # Try parsing the response as JSON\n",
    "                try:\n",
    "                    # Attempt to load the response as JSON (this is now more strict)\n",
    "                    quiz_output_dict = json.loads(quiz_output)  # Parse the output as JSON\n",
    "\n",
    "                    # Check if the generated quiz contains the correct number of MCQs\n",
    "                    quiz_list = quiz_output_dict.get(\"quiz\", [])\n",
    "                    if len(quiz_list) >= NUMBER:\n",
    "                        break  # Exit the loop if we have enough questions\n",
    "                    else:\n",
    "                        print(f\"Generated {len(quiz_list)} MCQs, but {NUMBER} are required. Re-generating...\")\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error parsing quiz output as JSON: {e}\")\n",
    "                    print(f\"Raw output received: {quiz_output}\")  # Print the raw output for debugging\n",
    "                    quiz_output_dict = {}\n",
    "        except Exception as e:\n",
    "            print(f\"Error during quiz generation: {e}\")\n",
    "            quiz_output_dict = {}\n",
    "\n",
    "    # If quiz output is empty or doesn't contain valid data, handle gracefully\n",
    "    if not quiz_output_dict:\n",
    "        print(\"Error: Generated quiz output is empty or invalid.\")\n",
    "        quiz = \"\"\n",
    "    else:\n",
    "        # Extract the generated quiz from the output\n",
    "        quiz = json.dumps(quiz_output_dict, indent=4)\n",
    "\n",
    "    # Step 3: Evaluate the quiz using the second chain (passing the quiz output from step 1)\n",
    "    if quiz:\n",
    "        evaluation_input = {\n",
    "            \"subject\": SUBJECT,\n",
    "            \"quiz\": quiz\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # Run the review chain to evaluate the quiz\n",
    "            review_output = review_chain.run(evaluation_input)\n",
    "\n",
    "            # Print the result (this will include both the quiz and the review)\n",
    "            print(\"Generated Quiz (as List):\")\n",
    "            \n",
    "            # Extract the quiz and represent it as a list of MCQs\n",
    "            quiz_dict = json.loads(quiz)  # Parse the quiz JSON again\n",
    "            for idx, item in enumerate(quiz_dict.get(\"quiz\", []), start=1):\n",
    "                mcq = item[\"mcq\"]\n",
    "                options = item[\"options\"]\n",
    "                answer = item[\"answer\"]\n",
    "                print(f\"{idx}. {mcq}\")\n",
    "                for option, choice in options.items():\n",
    "                    print(f\"    {option}: {choice}\")\n",
    "                print(f\"    Answer: {answer}\")\n",
    "                print()\n",
    "\n",
    "            print(\"\\nReview of the Quiz:\")\n",
    "            print(review_output)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during quiz evaluation: {e}\")\n",
    "    else:\n",
    "        print(\"No quiz generated, skipping evaluation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw response from quiz generation chain:\n",
      "{\n",
      "  \"quiz\": [\n",
      "    {\n",
      "      \"mcq\": \"Who coined the term 'machine learning' in 1959?\",\n",
      "      \"options\": {\n",
      "        \"a\": \"Donald Hebb\",\n",
      "        \"b\": \"Tom M. Mitchell\",\n",
      "        \"c\": \"Arthur Samuel\",\n",
      "        \"d\": \"Walter Pitts\"\n",
      "      },\n",
      "      \"answer\": \"c\"\n",
      "    },\n",
      "    {\n",
      "      \"mcq\": \"Which book published in 1949 introduced a theoretical neural structure that influenced the development of machine learning?\",\n",
      "      \"options\": {\n",
      "        \"a\": \"The Organization of Behavior\",\n",
      "        \"b\": \"Learning Machines\",\n",
      "        \"c\": \"Computing Machinery and Intelligence\",\n",
      "        \"d\": \"The History of Machine Learning\"\n",
      "      },\n",
      "      \"answer\": \"a\"\n",
      "    },\n",
      "    {\n",
      "      \"mcq\": \"What was the name of the experimental 'learning machine' developed by Raytheon Company in the early 1960s?\",\n",
      "      \"options\": {\n",
      "        \"a\": \"Cybertron\",\n",
      "        \"b\": \"NeuralNet\",\n",
      "        \"c\": \"AI Master\",\n",
      "        \"d\": \"Pattern Recognizer\"\n",
      "      },\n",
      "      \"answer\": \"a\"\n",
      "    },\n",
      "    {\n",
      "      \"mcq\": \"According to Tom M. Mitchell, what is the definition of a computer program learning from experience?\",\n",
      "      \"options\": {\n",
      "        \"a\": \"The program's ability to think like a human\",\n",
      "        \"b\": \"The program's ability to improve performance with experience\",\n",
      "        \"c\": \"The program's ability to analyze data\",\n",
      "        \"d\": \"The program's ability to perform complex calculations\"\n",
      "      },\n",
      "      \"answer\": \"b\"\n",
      "    },\n",
      "    {\n",
      "      \"mcq\": \"What are the two main objectives of modern-day machine learning?\",\n",
      "      \"options\": {\n",
      "        \"a\": \"To develop new programming languages\",\n",
      "        \"b\": \"To create artificial intelligence robots\",\n",
      "        \"c\": \"To classify data and make predictions based on models\",\n",
      "        \"d\": \"To design computer hardware\"\n",
      "      },\n",
      "      \"answer\": \"c\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Generated Quiz in DataFrame Format:\n",
      "                                            Question  \\\n",
      "0    Who coined the term 'machine learning' in 1959?   \n",
      "1  Which book published in 1949 introduced a theo...   \n",
      "2  What was the name of the experimental 'learnin...   \n",
      "3  According to Tom M. Mitchell, what is the defi...   \n",
      "4  What are the two main objectives of modern-day...   \n",
      "\n",
      "                                      Option A  \\\n",
      "0                                  Donald Hebb   \n",
      "1                 The Organization of Behavior   \n",
      "2                                    Cybertron   \n",
      "3  The program's ability to think like a human   \n",
      "4         To develop new programming languages   \n",
      "\n",
      "                                            Option B  \\\n",
      "0                                    Tom M. Mitchell   \n",
      "1                                  Learning Machines   \n",
      "2                                          NeuralNet   \n",
      "3  The program's ability to improve performance w...   \n",
      "4           To create artificial intelligence robots   \n",
      "\n",
      "                                            Option C  \\\n",
      "0                                      Arthur Samuel   \n",
      "1               Computing Machinery and Intelligence   \n",
      "2                                          AI Master   \n",
      "3              The program's ability to analyze data   \n",
      "4  To classify data and make predictions based on...   \n",
      "\n",
      "                                            Option D Answer  \n",
      "0                                       Walter Pitts      c  \n",
      "1                    The History of Machine Learning      a  \n",
      "2                                 Pattern Recognizer      a  \n",
      "3  The program's ability to perform complex calcu...      b  \n",
      "4                        To design computer hardware      c  \n",
      "\n",
      "Review of the Quiz:\n",
      "The Multiple Choice Quiz provided is well-structured and covers a range of important concepts in the field of machine learning. The questions are clear and concise, and the options provided are relevant to the topics being tested. \n",
      "\n",
      "In terms of complexity, the quiz seems well-suited for programming students who are familiar with the basics of machine learning. The questions require a good understanding of key historical figures, concepts, and terminology in the field. \n",
      "\n",
      "However, if the aim is to cater to a wider range of students or those at a beginner level, some adjustments could be made to simplify the language and context of the questions. For example, instead of asking \"Who coined the term 'machine learning' in 1959?\", the question could be rephrased as \"Who first used the term 'machine learning' in 1959?\" to make it more accessible to students with less prior knowledge.\n",
      "\n",
      "Overall, the quiz is informative and engaging, and with minor adjustments in language and tone, it can be made even more accessible to a broader audience of programming students.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd  # Import pandas for DataFrame handling\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "# Read text from file (you can provide any file path)\n",
    "file_path = r\"C:\\Users\\ASUS\\Desktop\\mcqgen\\data.txt\"\n",
    "\n",
    "# Read the content of the text file\n",
    "with open(file_path, 'r') as file:\n",
    "    TEXT = file.read()\n",
    "\n",
    "# Define the first template for quiz generation\n",
    "TEMPLATE = \"\"\"\n",
    "Text: {text}\n",
    "You are an expert MCQ maker. Given the above text, create exactly {number} multiple choice questions for {subject} students in a {tone} tone. \n",
    "Each question should be unique and related to the text. Ensure that all questions are clear, unambiguous, and well-formed, ensuring that each question is of good quality.\n",
    "The format for the response should strictly follow this structure:\n",
    "{{\n",
    "  \"quiz\": [\n",
    "    {{\n",
    "      \"mcq\": \"Your question here\",\n",
    "      \"options\": {{\n",
    "        \"a\": \"Choice A\",\n",
    "        \"b\": \"Choice B\",\n",
    "        \"c\": \"Choice C\",\n",
    "        \"d\": \"Choice D\"\n",
    "      }},\n",
    "      \"answer\": \"correct answer\"\n",
    "    }} \n",
    "  ]\n",
    "}}\n",
    "Ensure that there are {number} MCQs and no more than that. If less than {number} MCQs are generated, continue generating until the exact number is produced.\n",
    "\"\"\"\n",
    "\n",
    "# Define the second template for quiz evaluation\n",
    "TEMPLATE2 = \"\"\"\n",
    "You are an expert English grammarian and writer. Given a Multiple Choice Quiz for {subject} students, evaluate the complexity of the questions and provide a complete analysis of the quiz.\n",
    "If the quiz is not at par with the cognitive and analytical abilities of the students, update the quiz questions that need to be changed and adjust the tone so it perfectly fits the student abilities.\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the prompt templates\n",
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\"],\n",
    "    template=TEMPLATE\n",
    ")\n",
    "\n",
    "quiz_evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"subject\", \"quiz\"],  # Only subject and quiz are needed for review chain\n",
    "    template=TEMPLATE2\n",
    ")\n",
    "\n",
    "# Initialize the LLM model (e.g., OpenAI GPT-3.5)\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Create quiz generation chain (this generates the quiz)\n",
    "quiz_chain = LLMChain(llm=llm, prompt=quiz_generation_prompt)\n",
    "\n",
    "# Create review generation chain (this evaluates the quiz)\n",
    "review_chain = LLMChain(llm=llm, prompt=quiz_evaluation_prompt)\n",
    "\n",
    "# User-defined inputs\n",
    "NUMBER = 5  # Number of MCQs the user wants\n",
    "SUBJECT = \"Programming\"\n",
    "TONE = \"friendly\"\n",
    "\n",
    "# Define the callback function to log the result\n",
    "def openai_callback(result, *args, **kwargs):\n",
    "    print(\"OpenAI Callback triggered!\")\n",
    "    print(f\"Result: {result}\")\n",
    "\n",
    "# Use get_openai_callback directly and capture the output\n",
    "with get_openai_callback() as callback:\n",
    "    # Step 1: Generate the quiz using the first chain\n",
    "    input_data = {\n",
    "        \"text\": TEXT,  # Read text from file dynamically\n",
    "        \"number\": NUMBER,\n",
    "        \"subject\": SUBJECT,\n",
    "        \"tone\": TONE\n",
    "    }\n",
    "\n",
    "    # Run the quiz generation chain\n",
    "    quiz_output = \"\"\n",
    "    while True:\n",
    "        try:\n",
    "            # Generate the quiz\n",
    "            quiz_output = quiz_chain.run(input_data)  # Run the chain to generate the quiz\n",
    "\n",
    "            # Log the raw output from the quiz generation chain for inspection\n",
    "            print(\"Raw response from quiz generation chain:\")\n",
    "            print(quiz_output)\n",
    "\n",
    "            # Check if the output is empty\n",
    "            if not quiz_output.strip():\n",
    "                print(\"Error: Received empty response from the quiz generation model.\")\n",
    "                quiz_output_dict = {}\n",
    "            else:\n",
    "                # Try parsing the response as JSON\n",
    "                try:\n",
    "                    # Attempt to load the response as JSON (this is now more strict)\n",
    "                    quiz_output_dict = json.loads(quiz_output)  # Parse the output as JSON\n",
    "\n",
    "                    # Check if the generated quiz contains the correct number of MCQs\n",
    "                    quiz_list = quiz_output_dict.get(\"quiz\", [])\n",
    "                    if len(quiz_list) >= NUMBER:\n",
    "                        break  # Exit the loop if we have enough questions\n",
    "                    else:\n",
    "                        print(f\"Generated {len(quiz_list)} MCQs, but {NUMBER} are required. Re-generating...\")\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error parsing quiz output as JSON: {e}\")\n",
    "                    print(f\"Raw output received: {quiz_output}\")  # Print the raw output for debugging\n",
    "                    quiz_output_dict = {}\n",
    "        except Exception as e:\n",
    "            print(f\"Error during quiz generation: {e}\")\n",
    "            quiz_output_dict = {}\n",
    "\n",
    "    # If quiz output is empty or doesn't contain valid data, handle gracefully\n",
    "    if not quiz_output_dict:\n",
    "        print(\"Error: Generated quiz output is empty or invalid.\")\n",
    "        quiz = \"\"\n",
    "    else:\n",
    "        # Extract the generated quiz from the output\n",
    "        quiz = json.dumps(quiz_output_dict, indent=4)\n",
    "\n",
    "    # Step 3: Evaluate the quiz using the second chain (passing the quiz output from step 1)\n",
    "    if quiz:\n",
    "        evaluation_input = {\n",
    "            \"subject\": SUBJECT,\n",
    "            \"quiz\": quiz\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # Run the review chain to evaluate the quiz\n",
    "            review_output = review_chain.run(evaluation_input)\n",
    "\n",
    "            # Print the result (this will include both the quiz and the review)\n",
    "            print(\"\\nGenerated Quiz in DataFrame Format:\")\n",
    "\n",
    "            # Extract the quiz and represent it as a DataFrame\n",
    "            quiz_dict = json.loads(quiz)  # Parse the quiz JSON again\n",
    "            quiz_data = []\n",
    "\n",
    "            # Check if the quiz data exists and format it correctly\n",
    "            if \"quiz\" in quiz_dict:\n",
    "                for idx, item in enumerate(quiz_dict[\"quiz\"], start=1):\n",
    "                    mcq = item[\"mcq\"]\n",
    "                    options = item[\"options\"]\n",
    "                    answer = item[\"answer\"]\n",
    "\n",
    "                    # Append each question with its options and answer to the list\n",
    "                    quiz_data.append({\n",
    "                        \"Question\": mcq,\n",
    "                        \"Option A\": options.get('a', ''),\n",
    "                        \"Option B\": options.get('b', ''),\n",
    "                        \"Option C\": options.get('c', ''),\n",
    "                        \"Option D\": options.get('d', ''),\n",
    "                        \"Answer\": answer\n",
    "                    })\n",
    "\n",
    "            # Create a DataFrame from the quiz data\n",
    "            df = pd.DataFrame(quiz_data)\n",
    "\n",
    "            # Print the DataFrame\n",
    "            print(df)\n",
    "\n",
    "            print(\"\\nReview of the Quiz:\")\n",
    "            print(review_output)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during quiz evaluation: {e}\")\n",
    "    else:\n",
    "        print(\"No quiz generated, skipping evaluation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw response from quiz generation chain:\n",
      "{\n",
      "  \"quiz\": [\n",
      "    {\n",
      "      \"mcq\": \"Who coined the term 'machine learning' in 1959?\",\n",
      "      \"options\": {\n",
      "        \"a\": \"Donald Hebb\",\n",
      "        \"b\": \"Walter Pitts\",\n",
      "        \"c\": \"Arthur Samuel\",\n",
      "        \"d\": \"Warren McCulloch\"\n",
      "      },\n",
      "      \"answer\": \"c\"\n",
      "    },\n",
      "    {\n",
      "      \"mcq\": \"Which book introduced a theoretical neural structure that influenced the development of machine learning algorithms?\",\n",
      "      \"options\": {\n",
      "        \"a\": \"The Organization of Behavior\",\n",
      "        \"b\": \"Learning Machines\",\n",
      "        \"c\": \"Computing Machinery and Intelligence\",\n",
      "        \"d\": \"The History of Machine Learning\"\n",
      "      },\n",
      "      \"answer\": \"a\"\n",
      "    },\n",
      "    {\n",
      "      \"mcq\": \"In the 1960s, a learning machine called Cybertron was developed by which company?\",\n",
      "      \"options\": {\n",
      "        \"a\": \"IBM\",\n",
      "        \"b\": \"Raytheon Company\",\n",
      "        \"c\": \"Google\",\n",
      "        \"d\": \"Microsoft\"\n",
      "      },\n",
      "      \"answer\": \"b\"\n",
      "    },\n",
      "    {\n",
      "      \"mcq\": \"Who provided a formal definition of the algorithms studied in the machine learning field?\",\n",
      "      \"options\": {\n",
      "        \"a\": \"Tom M. Mitchell\",\n",
      "        \"b\": \"Alan Turing\",\n",
      "        \"c\": \"Arthur Samuel\",\n",
      "        \"d\": \"Donald Hebb\"\n",
      "      },\n",
      "      \"answer\": \"a\"\n",
      "    },\n",
      "    {\n",
      "      \"mcq\": \"What are the two main objectives of modern-day machine learning?\",\n",
      "      \"options\": {\n",
      "        \"a\": \"To write code efficiently\",\n",
      "        \"b\": \"To classify data and make predictions\",\n",
      "        \"c\": \"To design user interfaces\",\n",
      "        \"d\": \"To debug software\"\n",
      "      },\n",
      "      \"answer\": \"b\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Generated Quiz in DataFrame Format:\n",
      "                                            Question  \\\n",
      "0    Who coined the term 'machine learning' in 1959?   \n",
      "1  Which book introduced a theoretical neural str...   \n",
      "2  In the 1960s, a learning machine called Cybert...   \n",
      "3  Who provided a formal definition of the algori...   \n",
      "4  What are the two main objectives of modern-day...   \n",
      "\n",
      "                       Option A                               Option B  \\\n",
      "0                   Donald Hebb                           Walter Pitts   \n",
      "1  The Organization of Behavior                      Learning Machines   \n",
      "2                           IBM                       Raytheon Company   \n",
      "3               Tom M. Mitchell                            Alan Turing   \n",
      "4     To write code efficiently  To classify data and make predictions   \n",
      "\n",
      "                               Option C                         Option D  \\\n",
      "0                         Arthur Samuel                 Warren McCulloch   \n",
      "1  Computing Machinery and Intelligence  The History of Machine Learning   \n",
      "2                                Google                        Microsoft   \n",
      "3                         Arthur Samuel                      Donald Hebb   \n",
      "4             To design user interfaces                To debug software   \n",
      "\n",
      "  Answer  \n",
      "0      c  \n",
      "1      a  \n",
      "2      b  \n",
      "3      a  \n",
      "4      b  \n",
      "\n",
      "Quiz has been saved as a CSV file at C:\\Users\\ASUS\\Desktop\\mcqgen\\quiz_output.csv.\n",
      "\n",
      "Review of the Quiz:\n",
      "The above Multiple Choice Quiz for Programming students is well-constructed and covers a range of topics related to the history and concepts of machine learning. The questions are designed to test the students' knowledge and understanding of key figures, developments, and objectives in the field of machine learning.\n",
      "\n",
      "The complexity of the questions seems to be appropriate for programming students who are familiar with the basics of machine learning. The questions require a good grasp of the subject matter and an understanding of key concepts and historical developments in the field.\n",
      "\n",
      "However, to better align the quiz with the cognitive and analytical abilities of the students, some adjustments can be made to the tone and wording of the questions. For example, instead of using technical terms like \"theoretical neural structure,\" simpler language can be used to ensure that all students can easily understand and engage with the questions.\n",
      "\n",
      "Additionally, it might be helpful to provide more context or explanations for some of the answers to help students learn and understand the concepts better. This can enhance the educational value of the quiz and provide a more enriching learning experience for the students.\n",
      "\n",
      "Overall, the quiz is a good resource for testing and reinforcing students' knowledge of machine learning concepts. With some minor adjustments to the tone and wording of the questions, it can be even more effective in engaging students and aiding in their learning process.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd  # Import pandas for DataFrame handling\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "# Read text from file (you can provide any file path)\n",
    "file_path = r\"C:\\Users\\ASUS\\Desktop\\mcqgen\\data.txt\"\n",
    "\n",
    "# Read the content of the text file\n",
    "with open(file_path, 'r') as file:\n",
    "    TEXT = file.read()\n",
    "\n",
    "# Define the first template for quiz generation\n",
    "TEMPLATE = \"\"\"\n",
    "Text: {text}\n",
    "You are an expert MCQ maker. Given the above text, create exactly {number} multiple choice questions for {subject} students in a {tone} tone. \n",
    "Each question should be unique and related to the text. Ensure that all questions are clear, unambiguous, and well-formed, ensuring that each question is of good quality.\n",
    "The format for the response should strictly follow this structure:\n",
    "{{\n",
    "  \"quiz\": [\n",
    "    {{\n",
    "      \"mcq\": \"Your question here\",\n",
    "      \"options\": {{\n",
    "        \"a\": \"Choice A\",\n",
    "        \"b\": \"Choice B\",\n",
    "        \"c\": \"Choice C\",\n",
    "        \"d\": \"Choice D\"\n",
    "      }},\n",
    "      \"answer\": \"correct answer\"\n",
    "    }} \n",
    "  ]\n",
    "}}\n",
    "Ensure that there are {number} MCQs and no more than that. If less than {number} MCQs are generated, continue generating until the exact number is produced.\n",
    "\"\"\"\n",
    "\n",
    "# Define the second template for quiz evaluation\n",
    "TEMPLATE2 = \"\"\"\n",
    "You are an expert English grammarian and writer. Given a Multiple Choice Quiz for {subject} students, evaluate the complexity of the questions and provide a complete analysis of the quiz.\n",
    "If the quiz is not at par with the cognitive and analytical abilities of the students, update the quiz questions that need to be changed and adjust the tone so it perfectly fits the student abilities.\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the prompt templates\n",
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\"],\n",
    "    template=TEMPLATE\n",
    ")\n",
    "\n",
    "quiz_evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"subject\", \"quiz\"],  # Only subject and quiz are needed for review chain\n",
    "    template=TEMPLATE2\n",
    ")\n",
    "\n",
    "# Initialize the LLM model (e.g., OpenAI GPT-3.5)\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Create quiz generation chain (this generates the quiz)\n",
    "quiz_chain = LLMChain(llm=llm, prompt=quiz_generation_prompt)\n",
    "\n",
    "# Create review generation chain (this evaluates the quiz)\n",
    "review_chain = LLMChain(llm=llm, prompt=quiz_evaluation_prompt)\n",
    "\n",
    "# User-defined inputs\n",
    "NUMBER = 5  # Number of MCQs the user wants\n",
    "SUBJECT = \"Programming\"\n",
    "TONE = \"friendly\"\n",
    "\n",
    "# Define the callback function to log the result\n",
    "def openai_callback(result, *args, **kwargs):\n",
    "    print(\"OpenAI Callback triggered!\")\n",
    "    print(f\"Result: {result}\")\n",
    "\n",
    "# Use get_openai_callback directly and capture the output\n",
    "with get_openai_callback() as callback:\n",
    "    # Step 1: Generate the quiz using the first chain\n",
    "    input_data = {\n",
    "        \"text\": TEXT,  # Read text from file dynamically\n",
    "        \"number\": NUMBER,\n",
    "        \"subject\": SUBJECT,\n",
    "        \"tone\": TONE\n",
    "    }\n",
    "\n",
    "    # Run the quiz generation chain\n",
    "    quiz_output = \"\"\n",
    "    while True:\n",
    "        try:\n",
    "            # Generate the quiz\n",
    "            quiz_output = quiz_chain.run(input_data)  # Run the chain to generate the quiz\n",
    "\n",
    "            # Log the raw output from the quiz generation chain for inspection\n",
    "            print(\"Raw response from quiz generation chain:\")\n",
    "            print(quiz_output)\n",
    "\n",
    "            # Check if the output is empty\n",
    "            if not quiz_output.strip():\n",
    "                print(\"Error: Received empty response from the quiz generation model.\")\n",
    "                quiz_output_dict = {}\n",
    "            else:\n",
    "                # Try parsing the response as JSON\n",
    "                try:\n",
    "                    # Attempt to load the response as JSON (this is now more strict)\n",
    "                    quiz_output_dict = json.loads(quiz_output)  # Parse the output as JSON\n",
    "\n",
    "                    # Check if the generated quiz contains the correct number of MCQs\n",
    "                    quiz_list = quiz_output_dict.get(\"quiz\", [])\n",
    "                    if len(quiz_list) >= NUMBER:\n",
    "                        break  # Exit the loop if we have enough questions\n",
    "                    else:\n",
    "                        print(f\"Generated {len(quiz_list)} MCQs, but {NUMBER} are required. Re-generating...\")\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error parsing quiz output as JSON: {e}\")\n",
    "                    print(f\"Raw output received: {quiz_output}\")  # Print the raw output for debugging\n",
    "                    quiz_output_dict = {}\n",
    "        except Exception as e:\n",
    "            print(f\"Error during quiz generation: {e}\")\n",
    "            quiz_output_dict = {}\n",
    "\n",
    "    # If quiz output is empty or doesn't contain valid data, handle gracefully\n",
    "    if not quiz_output_dict:\n",
    "        print(\"Error: Generated quiz output is empty or invalid.\")\n",
    "        quiz = \"\"\n",
    "    else:\n",
    "        # Extract the generated quiz from the output\n",
    "        quiz = json.dumps(quiz_output_dict, indent=4)\n",
    "\n",
    "    # Step 3: Evaluate the quiz using the second chain (passing the quiz output from step 1)\n",
    "    if quiz:\n",
    "        evaluation_input = {\n",
    "            \"subject\": SUBJECT,\n",
    "            \"quiz\": quiz\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # Run the review chain to evaluate the quiz\n",
    "            review_output = review_chain.run(evaluation_input)\n",
    "\n",
    "            # Print the result (this will include both the quiz and the review)\n",
    "            print(\"\\nGenerated Quiz in DataFrame Format:\")\n",
    "\n",
    "            # Extract the quiz and represent it as a DataFrame\n",
    "            quiz_dict = json.loads(quiz)  # Parse the quiz JSON again\n",
    "            quiz_data = []\n",
    "\n",
    "            # Check if the quiz data exists and format it correctly\n",
    "            if \"quiz\" in quiz_dict:\n",
    "                for idx, item in enumerate(quiz_dict[\"quiz\"], start=1):\n",
    "                    mcq = item[\"mcq\"]\n",
    "                    options = item[\"options\"]\n",
    "                    answer = item[\"answer\"]\n",
    "\n",
    "                    # Append each question with its options and answer to the list\n",
    "                    quiz_data.append({\n",
    "                        \"Question\": mcq,\n",
    "                        \"Option A\": options.get('a', ''),\n",
    "                        \"Option B\": options.get('b', ''),\n",
    "                        \"Option C\": options.get('c', ''),\n",
    "                        \"Option D\": options.get('d', ''),\n",
    "                        \"Answer\": answer\n",
    "                    })\n",
    "\n",
    "            # Create a DataFrame from the quiz data\n",
    "            df = pd.DataFrame(quiz_data)\n",
    "\n",
    "            # Print the DataFrame\n",
    "            print(df)\n",
    "\n",
    "            # Save the DataFrame to a CSV file\n",
    "            csv_file_path = r\"C:\\Users\\ASUS\\Desktop\\mcqgen\\quiz_output.csv\"  # Specify your desired CSV file path\n",
    "            df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "            print(f\"\\nQuiz has been saved as a CSV file at {csv_file_path}.\")\n",
    "\n",
    "            print(\"\\nReview of the Quiz:\")\n",
    "            print(review_output)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during quiz evaluation: {e}\")\n",
    "    else:\n",
    "        print(\"No quiz generated, skipping evaluation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01_16_2025_00_01_32'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().strftime('%m_%d_%Y_%H_%M_%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
